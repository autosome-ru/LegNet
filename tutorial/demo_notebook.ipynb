{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5cac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_fuctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e5796",
   "metadata": {},
   "source": [
    "# **LegNet**: solving the sequence-to-expression problem with SOTA convolutional networks\n",
    "\n",
    "This is the tutorial demonstrating how LegNet can be practically used with the data from yeast gigantic parallel reporter assays.\n",
    "\n",
    "Please don't hesitate to ask questions or share any feedback: dmitrypenzar1996@gmail.com\n",
    "\n",
    "The code below allows us to train the LegNet model to predict gene expression from promoter sequences using the data from gigantic yeast parallel reporter assays ( [Sort-Seq](https://www.cell.com/cell-systems/fulltext/S2405-4712(16)30292-7?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS2405471216302927%3Fshowall%3Dtrue) ).\n",
    "\n",
    "In our tutorial, we follow the setup of the [DREAM 2022 promoter expression challenge](https://www.synapse.org\\#!Synapse:syn28469146/wiki/617075).\n",
    "\n",
    "To perform the model training, you need a table with sequences and corresponding expression values. A toy example is [expression measured in yeast grown in complex medium](https://zenodo.org/record/4436477/files/complex_media_training_data_Glu.txt?download=1) or [expression measure in yeast grown in defined medium](https://zenodo.org/record/4436477/files/defined_media_training_data_SC_Ura.txt?download=1) in the [Zenodo record](https://zenodo.org/record/4436477#.Y5QgZOxBy3J), see [Vaishnav et al](https://doi.org/10.1038/s41586-022-04506-6) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c90eb0",
   "metadata": {},
   "source": [
    "## Specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2009b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'model' # folder that will contatin all outputs {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75da178",
   "metadata": {},
   "source": [
    "### 1. Data\n",
    "\n",
    "The tab-separated training data must use the following format:\n",
    "\n",
    "* First column: sequence. Second column: expression value. Third column: fold (optional).\n",
    "* The data should be provided without any extra header line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2bb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_training_data = 'path' # file location or url {type:\"string\"}\n",
    "\n",
    "delimiter = \"tab\" # [\"tab\", \",\", \";\"] {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8439776",
   "metadata": {},
   "source": [
    "If the sequences have unequal lengths it's **necessary** to use padding. The padding is possible only if the surrounding plasmid sequence is provided as a string where the target promoter sequence is denoted with Ns. (Example: atgcNNNatcg.)\n",
    "\n",
    "Specify the sequence length without adapters.\n",
    "\n",
    "Seqsize is the resulting sequence size after padding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16466abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"plasmid.json\") as json_file:\n",
    "    plasmid = json.load(json_file)\n",
    "\n",
    "left_adapter = \"TGCATTTTTTTCACATC\" # {type:\"string\"}\n",
    "right_adapter = \"GGTTACGGCTGTT\" # {type:\"string\"}\n",
    "\n",
    "sequence_len_no_adapters = 80 # {type:\"integer\"}\n",
    "\n",
    "seqsize = 150 # {type:\"integer\"}\n",
    "\n",
    "if len(plasmid) == 0:\n",
    "    print('Padding will not be used because the plasmid sequence is unavailable.')\n",
    "else:\n",
    "    print('Padding will be used because the plasmid sequence has len > 0.')\n",
    "\n",
    "assert sequence_len_no_adapters <= seqsize, \"Seqsize cannot be less than the sequence length without adapters.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3eed4f",
   "metadata": {},
   "source": [
    "### 2.1. Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfefeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "final_ch: number of channels of the final convolutional layer. \n",
    "\n",
    "For challenge task it corresponds to the number of expression bins.\n",
    "'''\n",
    "final_ch = 18 # {type:\"integer\"}\n",
    "\n",
    "'''\n",
    "Number of channels for EffNet-like blocks\n",
    "'''\n",
    "blocks = [256, 128, 128, 64, 64, 64, 64] # {type:\"list\"}\n",
    "\n",
    "'''\n",
    "Kernel size of convolutional layers\n",
    "'''\n",
    "ks = 7 # {type:\"integer\"}\n",
    "\n",
    "'''\n",
    "Number of channels in a middle/high-dimensional convolutional layer of an EffNet-like block\n",
    "'''\n",
    "resize_factor = 4 # {type:\"integer\"}\n",
    "\n",
    "'''\n",
    "Reduction number used in SELayer\n",
    "'''\n",
    "se_reduction = 4 # {type:\"integer\"}\n",
    "\n",
    "'''\n",
    "BatchNorm momentum\n",
    "'''\n",
    "bn_momentum = .1 # {type:\"float\"} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d08f0",
   "metadata": {},
   "source": [
    "### 2.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27282f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'kl' # [\"mse\", \"kl\"] {type:\"string\"}\n",
    "\n",
    "epoch_num = 450 # {type:\"integer\"}\n",
    "\n",
    "batch_per_epoch = 1000 # {type:\"integer\"}\n",
    "\n",
    "optimizer_name = \"adamw\" # [\"adam\", \"adamw\", \"rmsprop\"] {type:\"string\"}\n",
    "\n",
    "weight_decay = 0.01 # {type:\"float\"}\n",
    "\n",
    "'''\n",
    "Note: lr will be set manually via range test run for few epochs to find out good learning rate.\n",
    "Warning: running range test will require you to manually set lr based on a training plot.\n",
    "'''\n",
    "\n",
    "train_batch_size = 1024 # {type:\"integer\"}\n",
    "valid_batch_size = 1024 # {type:\"integer\"}\n",
    "\n",
    "train_workers = 8 # {type:\"integer\"}\n",
    "valid_workers = 8 # {type:\"integer\"}\n",
    "\n",
    "'''\n",
    "Additional binary channel with singleton information.\n",
    "Integer expression values are considered as singletons measured in the GPRA experiment only once. \n",
    "'''\n",
    "use_single_channel = True # [\"False\", \"True\"] {type:\"raw\"}\n",
    "\n",
    "'''\n",
    "Dataset augmentation by reversing input sequences and adding binary channel.\n",
    "'''\n",
    "use_reverse_channel = True # [\"False\", \"True\"] {type:\"raw\"}\n",
    "\n",
    "'''\n",
    "Additional substrate channel. Can be used to mix the data from yeast grown in different media.\n",
    "'''\n",
    "use_multisubstate_channel = True # [\"False\", \"True\"] {type:\"raw\"}\n",
    "\n",
    "'''\n",
    "Whether to split the training data into train and validation.\n",
    "'''\n",
    "foldify = True # [\"False\", \"True\"] {type:\"raw\"}\n",
    "\n",
    "'''\n",
    "Whether to turn on validation.\n",
    "'''\n",
    "use_validation = False # [\"False\", \"True\"] {type:\"raw\"}\n",
    "\n",
    "seed = 42 # {type:\"integer\"}\n",
    "\n",
    "gpu = 1 # {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718a8545",
   "metadata": {},
   "source": [
    "## The main code of the model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b858470",
   "metadata": {},
   "source": [
    "Below we present approach step-by-step, briefly describing data preprocessing and the model architecture.\n",
    "\n",
    "Note: additional code is located in the `helper_fuctions` module. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b99af3",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e50d616",
   "metadata": {},
   "source": [
    "#### Input vector structure\n",
    "\n",
    "The training sequences were padded on the 5’ end with nucleotides from the corresponding plasmid to the uniform total length (`preprocess_data`) and encoded into 4-dimensional vectors using **one-hot encoding** (`Seq2Tensor`). \n",
    "\n",
    "We have considered the sequences with integer scores as **singletons**, i.e. they likely have been observed only once, while non-integer scores were obtained by averaging two or more observations. To supply this information to the model, we introduced a binary `is_singleton` channel (1 for singletons, 0 for other training sequences). The final predictions for evaluation were made by specifying `is_singleton=0`.\n",
    "\n",
    "Since the regulatory elements are often asymmetric relative to the transcription start sites, different scores were expected for direct and reverse complementary strands of a particular sequence. Thus, the data was augmented by providing each sequence twice in native and **reverse complementary** form, specifying 0 and 1, respectively, in an additional `is_reverse` channel. The test-time augmentation was to average the predictions made for direct (`is_reverse=0`) and reverse complementary (`is_reverse=1`) input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9cbd5c",
   "metadata": {},
   "source": [
    "<img src=\"img/Input.jpg\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2575619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, seqsize):\n",
    "    '''\n",
    "    Training sequences are padded on the 5’ end with nucleotides \n",
    "    from the corresponding plasmid to the uniform total length.\n",
    "    '''\n",
    "    \n",
    "    data = data.copy()\n",
    "    INSERT_START = plasmid.find('N' * sequence_len_no_adapters)\n",
    "    \n",
    "    #take the left part of the plasmid\n",
    "    add_part = plasmid[INSERT_START-seqsize:INSERT_START]\n",
    "    \n",
    "    # cut left adapter and append the plasmid part\n",
    "    data.seq = data.seq.apply(lambda x:  add_part + x[len(left_adapter):])\n",
    "    \n",
    "    # reduce sequence size to seqsize\n",
    "    data.seq = data.seq.str.slice(-seqsize, None)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Tensor(nn.Module):\n",
    "    '''\n",
    "    Encode sequences using one-hot encoding after preprocessing.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, seq):\n",
    "        if isinstance(seq, torch.FloatTensor):\n",
    "            return seq\n",
    "        seq = [n2id(x) for x in seq]\n",
    "        code = torch.from_numpy(np.array(seq))\n",
    "        code = F.one_hot(code, num_classes=5) # 5th class is N\n",
    "        \n",
    "        code[code[:, 4] == 1] = 0.25 # encode Ns with .25\n",
    "        code = code[:, :4].float() \n",
    "        return code.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57af48",
   "metadata": {},
   "source": [
    "#### The formal description of the challenge problem\n",
    "\n",
    "We reformulated the sequence-to-expression problem arising in the GPRA ([Sort-Seq](https://www.cell.com/cell-systems/fulltext/S2405-4712(16)30292-7?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS2405471216302927%3Fshowall%3Dtrue)) analysis as a soft classification task by transforming expression estimates to class probabilities.\n",
    "\n",
    "Given a measured expression $e$, assume that the real expression is normally distributed: $\\rho \\sim N(\\mu = e + 0.5, sd=0.5)$. \n",
    "\n",
    "For each class i from 1 to 16 defined by an original measurement bin, a probability of the class is the probability of $[i, i+1)$, where 0 and 17 bins are special cases with  $(-\\inf,0]$ and $[17,+\\inf)$, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8188d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# points to get cdf from normal distribution, see below\n",
    "POINTS = np.array([-np.inf, *range(1, final_ch, 1), np.inf])\n",
    "\n",
    "class SeqDatasetProb(Dataset):\n",
    "    \n",
    "    \"\"\" Sequence dataset. \"\"\"\n",
    "    \n",
    "    def __init__(self, ds, seqsize, use_single_channel, use_reverse_channel, use_multisubstate_channel, shift=0.5, scale=0.5):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ds : pd.DataFrame\n",
    "            Training dataset.\n",
    "        seqsize : int\n",
    "            Constant sequence length.\n",
    "        use_single_channel : bool\n",
    "            If True, additional binary channel with singleton information is used.\n",
    "        use_reverse_channel : bool\n",
    "            If True, additional reverse augmentation is used.\n",
    "        use_multisubstate_channel : bool\n",
    "            If True, additional substrate channel is used.\n",
    "        shift : float, optional\n",
    "            Assumed sd of real expression normal distribution.\n",
    "        scale : float, optional\n",
    "            Assumed scale of real expression normal distribution.\n",
    "        \"\"\"\n",
    "        self.ds = ds\n",
    "        self.seqsize = seqsize\n",
    "        self.totensor = Seq2Tensor() \n",
    "        self.shift = shift \n",
    "        self.scale = scale\n",
    "        self.use_single_channel = use_single_channel\n",
    "        self.use_reverse_channel = use_reverse_channel\n",
    "        self.use_multisubstate_channel = use_multisubstate_channel\n",
    "        \n",
    "    def transform(self, x):\n",
    "        assert isinstance(x, str)\n",
    "        assert len(x) == self.seqsize\n",
    "        return self.totensor(x)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\n",
    "        Output\n",
    "        ----------\n",
    "        X: torch.Tensor    \n",
    "            Create one-hot encoding tensor with reverse and singleton channels if required.\n",
    "        probs: np.ndarray\n",
    "            Given a measured expression, we assume that the real expression is normally distributed\n",
    "            with mean=`bin` and sd=`shift`. \n",
    "            Resulting `probs` vector contains probabilities that correspond to each class (bin).     \n",
    "        bin: float \n",
    "            Training expression value\n",
    "        \"\"\"\n",
    "        seq = self.transform(self.ds.seq.values[i])\n",
    "        to_concat = [seq]\n",
    "        \n",
    "        # add reverse augmentation channel\n",
    "        if self.use_reverse_channel:\n",
    "            rev = torch.full( (1, self.seqsize), self.ds.rev.values[i], dtype=torch.float32)\n",
    "            to_concat.append(rev)\n",
    "            \n",
    "        # add singleton channel\n",
    "        if self.use_single_channel:\n",
    "            single = torch.full( (1, self.seqsize) , self.ds.is_singleton.values[i], dtype=torch.float32)\n",
    "            to_concat.append(single)\n",
    "            \n",
    "        # add multiclass channel\n",
    "        if self.use_multisubstate_channel:\n",
    "            substrate = torch.full( (1, self.seqsize) , self.ds.substrate.values[i], dtype=torch.float32)\n",
    "            to_concat.append(substrate)\n",
    "        \n",
    "        # create final tensor\n",
    "        if len(to_concat) > 1:\n",
    "            X = torch.concat(to_concat, dim=0)\n",
    "        else:\n",
    "            X = seq\n",
    "            \n",
    "        bin = self.ds.bin.values[i]\n",
    "        \n",
    "        # generate probabilities corresponding to each class\n",
    "        norm = scipy.stats.norm(loc=bin + self.shift, scale=self.scale)\n",
    "        \n",
    "        cumprobs = norm.cdf(POINTS)\n",
    "        probs = cumprobs[1:] - cumprobs[:-1]\n",
    "        return X, probs, bin\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420f9f6",
   "metadata": {},
   "source": [
    "### Trainer code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39cd06",
   "metadata": {},
   "source": [
    "`train_step` function of `create_trainer` illustrates the principle of the training procedure.\n",
    "\n",
    "The output of the model is a vector containing `final_ch` **probabilities** that correspond to each class (bin) and **expression value** where\n",
    "\n",
    "$expression = \\sum_{i=0}^{final\\_ch} i * p_i$ (soft-argmax operation). \n",
    "\n",
    "Only probabilities vector is used for calculating loss during training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainer(model, \n",
    "                   optimizer,\n",
    "                   scheduler,  \n",
    "                   criterion, \n",
    "                   device, \n",
    "                   model_dir,\n",
    "                   use_validation,\n",
    "                   valid_dl=None\n",
    "                  ):\n",
    "    model_dir = Path(model_dir)\n",
    "    model_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    train_mse =  MeanSquaredError()\n",
    "    train_pearson = PearsonMetric()\n",
    "    train_spearman = SpearmanMetric()\n",
    "    \n",
    "    def train_step(trainer, batch):\n",
    "        nonlocal model\n",
    "        if not model.training:\n",
    "            model = model.train()\n",
    "            \n",
    "        # unpack one-hot encoding tensor with additional channels, probabilities and expression\n",
    "        X, y_probs, y = batch \n",
    "        X = X.to(device)\n",
    "        y_probs = y_probs.float().to(device)\n",
    "        \n",
    "        # the output of the model consists of probabilities vector and expression from these probabilities\n",
    "        # only probabilities vector is used for training\n",
    "        logprobs, y_pred = model(X) \n",
    "        loss = criterion(logprobs, y_probs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()                                                                                         \n",
    "        out = (y_pred.detach().cpu(), y)\n",
    "        \n",
    "        # calculate training metrics based on calculated expression\n",
    "        train_mse.update(out)\n",
    "        train_pearson.update(out)\n",
    "        train_spearman.update(out)\n",
    "               \n",
    "        return loss.item()\n",
    "    \n",
    "    trainer = Engine(train_step)\n",
    "    \n",
    "    @trainer.on(Events.STARTED)\n",
    "    def prepare_epoch(engine): \n",
    "        engine.state.metrics['train_pearson'] = -np.inf\n",
    "        engine.state.metrics['train_mse'] = -np.inf\n",
    "        engine.state.metrics['train_spearman'] = -np.inf\n",
    "        if use_validation:\n",
    "            engine.state.metrics['val_pearson'] = -np.inf\n",
    "            engine.state.metrics['val_mse'] = -np.inf\n",
    "            engine.state.metrics['val_spearman'] = -np.inf\n",
    "\n",
    "    def evaluate(engine, batch):\n",
    "        nonlocal model\n",
    "        if model.training:\n",
    "            model = model.eval()\n",
    "        with torch.no_grad():\n",
    "            X, y_probs, y = batch\n",
    "            X = X.to(device)\n",
    "            y = y.float().to(device)\n",
    "            _, y_pred = model(X)\n",
    "        return y_pred.cpu(), y.cpu()\n",
    "\n",
    "    evaluator = Engine(evaluate)\n",
    "\n",
    "    MeanSquaredError().attach(evaluator, 'mse')\n",
    "    p = PearsonMetric()\n",
    "    p.attach(evaluator, 'pearson')\n",
    "    s = SpearmanMetric()\n",
    "    s.attach(evaluator, 'spearman')\n",
    "    \n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def validate(engine):\n",
    "        p.reset()\n",
    "            \n",
    "        engine.state.metrics['train_mse'] = train_mse.compute()\n",
    "        engine.state.metrics['train_pearson'] = train_pearson.compute()\n",
    "        engine.state.metrics['train_spearman'] = train_spearman.compute()\n",
    "        train_mse.reset()\n",
    "        train_pearson.reset()\n",
    "        train_spearman.reset()\n",
    "        \n",
    "        if use_validation and valid_dl is not None:\n",
    "            evaluator.run(valid_dl, max_epochs=1)\n",
    "            for name, value in evaluator.state.metrics.items():\n",
    "                engine.state.metrics[f\"val_{name}\"] = value\n",
    "        \n",
    "        score_path = model_dir / f\"scores_{engine.state.epoch}.json\"\n",
    "        with open(score_path, \"w\") as outp:\n",
    "            json.dump(engine.state.metrics, outp)\n",
    "\n",
    "    \n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def dump_model(engine):\n",
    "        model_path = model_dir / f\"model_{engine.state.epoch}.pth\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        optimizer_path = model_dir / f\"optimizer_{engine.state.epoch}.pth\"\n",
    "        torch.save(optimizer.state_dict(), optimizer_path)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler_path = model_dir / f\"scheduler_{engine.state.epoch}.pth\"\n",
    "            torch.save(scheduler.state_dict(), scheduler_path)\n",
    "           \n",
    "            \n",
    "    pbar = ProgressBar(persist=True)\n",
    "    pbar.attach(trainer, [\"train_mse\", \"train_pearson\", \"train_spearman\", ], \n",
    "                output_transform=lambda x: {'batch_loss': x}, \n",
    "                )\n",
    "    return trainer, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0afecd",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637627b",
   "metadata": {},
   "source": [
    "Our model is based upon a fully-convolutional neural network architecture inspired by EfficientNetV2 with selected features  from DenseNet and additional custom blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8dd604",
   "metadata": {},
   "source": [
    "![OveralArchitecture](img/A.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed697793",
   "metadata": {},
   "source": [
    "Efficient-net like convblock comprises features of EfficientNetV2. The **Squeeze and Excitation (SE) block** is a modification of that of the original EfficientNetV2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddd36db",
   "metadata": {},
   "source": [
    "<img src=\"img/SEblock.jpg\" width=\"200\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74bb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excite layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inp : int\n",
    "        Middle layer size.\n",
    "    oup : int\n",
    "        Input and ouput size.\n",
    "    reduction : int, optional\n",
    "        Reduction parameter. The default is 4.\n",
    "    \"\"\"\n",
    "    def __init__(self, inp, oup, reduction=4):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(oup, int(inp // reduction)),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(int(inp // reduction), int(inp // reduction)),\n",
    "                Concater(Bilinear(int(inp // reduction), int(inp // reduction // 2), rank=0.5, bias=True)),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(int(inp // reduction) +  int(inp // reduction // 2), oup),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, = x.size()\n",
    "        y = x.view(b, c, -1).mean(dim=2)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b001794a",
   "metadata": {},
   "source": [
    "The **bilinear block** is re-implemented using tensorly-pytorch instead of the default PyTorch version because of the tensor regularization functionality of the latter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bilinear(nn.Module):\n",
    "    \"\"\"\n",
    "    Bilinear layer introduces pairwise product to a NN to model possible combinatorial effects.\n",
    "    This particular implementation attempts to leverage the number of parameters via low-rank tensor decompositions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of input features.\n",
    "    out : int, optional\n",
    "        Number of output features. If None, assumed to be equal to the number of input features. The default is None.\n",
    "    rank : float, optional\n",
    "        Fraction of maximal to rank to be used in tensor decomposition. The default is 0.05.\n",
    "    bias : bool, optional\n",
    "        If True, bias is used. The default is False.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n: int, out=None, rank=0.05, bias=False):        \n",
    "        super().__init__()\n",
    "        if out is None:\n",
    "            out = (n, )\n",
    "        self.trl = TRL((n, n), out, bias=bias, rank=rank)\n",
    "        self.trl.weight = self.trl.weight.normal_(std=0.00075)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(dim=-1)\n",
    "        return self.trl(x @ x.transpose(-1, -2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e458f9",
   "metadata": {},
   "source": [
    "Here is presented the structure of full **EfficientNet-like convblock**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab21ffd",
   "metadata": {},
   "source": [
    "<img src=\"img/C.jpg\" width=\"200\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533a3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqNN(nn.Module):\n",
    "    \"\"\"\n",
    "    LegNet neural network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seqsize : int\n",
    "        Sequence length.\n",
    "    use_single_channel : bool\n",
    "        If True, singleton channel is used.\n",
    "    block_sizes : list, optional\n",
    "        List containing block sizes. The default is [256, 256, 128, 128, 64, 64, 32, 32].\n",
    "    ks : int, optional\n",
    "        Kernel size of convolutional layers. The default is 5.\n",
    "    resize_factor : int, optional\n",
    "        Resize factor used in a high-dimensional middle layer of an EffNet-like block. The default is 4.\n",
    "    activation : nn.Module, optional\n",
    "        Activation function. The default is nn.SiLU.\n",
    "    filter_per_group : int, optional\n",
    "        Number of filters per group in a middle convolutiona layer of an EffNet-like block. The default is 2.\n",
    "    se_reduction : int, optional\n",
    "        Reduction number used in SELayer. The default is 4.\n",
    "    final_ch : int, optional\n",
    "        Number of channels in the final output convolutional channel. The default is 18.\n",
    "    bn_momentum : float, optional\n",
    "        BatchNorm momentum. The default is 0.1.\n",
    "    \"\"\"\n",
    "    __constants__ = ('resize_factor')\n",
    "    \n",
    "    def __init__(self, \n",
    "                seqsize, \n",
    "                use_single_channel, \n",
    "                use_reverse_channel,\n",
    "                use_multisubstate_channel,\n",
    "                block_sizes=[256, 256, 128, 128, 64, 64, 32, 32], \n",
    "                ks=5, \n",
    "                resize_factor=4, \n",
    "                activation=nn.SiLU,\n",
    "                filter_per_group=2,\n",
    "                se_reduction=4,\n",
    "                final_ch=18,\n",
    "                bn_momentum=0.1):        \n",
    "        super().__init__()\n",
    "        self.block_sizes = block_sizes\n",
    "        self.resize_factor = resize_factor\n",
    "        self.se_reduction = se_reduction\n",
    "        self.seqsize = seqsize\n",
    "        self.use_single_channel = use_single_channel\n",
    "        self.use_reverse_channel = use_reverse_channel\n",
    "        self.use_multisubstate_channel = use_multisubstate_channel\n",
    "        self.final_ch = final_ch\n",
    "        self.bn_momentum = bn_momentum\n",
    "        seqextblocks = OrderedDict()\n",
    "\n",
    "        in_channels_first_block = 4\n",
    "        if self.use_single_channel:\n",
    "            in_channels_first_block += 1\n",
    "        if self.use_reverse_channel:\n",
    "            in_channels_first_block += 1\n",
    "        if self.use_multisubstate_channel:\n",
    "            in_channels_first_block += 1\n",
    "        \n",
    "        block = nn.Sequential(\n",
    "                       nn.Conv1d(\n",
    "                            in_channels=in_channels_first_block,\n",
    "                            out_channels=block_sizes[0],\n",
    "                            kernel_size=ks,\n",
    "                            padding='same',\n",
    "                            bias=False\n",
    "                       ),\n",
    "                       nn.BatchNorm1d(block_sizes[0], momentum=self.bn_momentum),\n",
    "                       activation()\n",
    "        )\n",
    "        seqextblocks[f'blc0'] = block\n",
    "\n",
    "        \n",
    "        for ind, (prev_sz, sz) in enumerate(zip(block_sizes[:-1], block_sizes[1:])):\n",
    "            block = nn.Sequential(\n",
    "                        nn.Conv1d(\n",
    "                            in_channels=prev_sz,\n",
    "                            out_channels=sz * self.resize_factor,\n",
    "                            kernel_size=1,\n",
    "                            padding='same',\n",
    "                            bias=False\n",
    "                       ),\n",
    "                       nn.BatchNorm1d(sz * self.resize_factor, momentum=self.bn_momentum),\n",
    "                       activation(),\n",
    "                       \n",
    "                       nn.Conv1d(\n",
    "                            in_channels=sz * self.resize_factor,\n",
    "                            out_channels=sz * self.resize_factor,\n",
    "                            kernel_size=ks,\n",
    "                            groups=sz * self.resize_factor // filter_per_group,\n",
    "                            padding='same',\n",
    "                            bias=False\n",
    "                       ),\n",
    "                       nn.BatchNorm1d(sz * self.resize_factor, momentum=self.bn_momentum),\n",
    "                       activation(),\n",
    "                \n",
    "                       SELayer(prev_sz, sz * self.resize_factor, reduction=self.se_reduction),\n",
    "                \n",
    "                       nn.Conv1d(\n",
    "                            in_channels=sz * self.resize_factor,\n",
    "                            out_channels=prev_sz,\n",
    "                            kernel_size=1,\n",
    "                            padding='same',\n",
    "                            bias=False\n",
    "                       ),\n",
    "                       nn.BatchNorm1d(prev_sz, momentum=self.bn_momentum),\n",
    "                       activation(),\n",
    "            \n",
    "            )\n",
    "            seqextblocks[f'inv_res_blc{ind}'] = block\n",
    "            block = nn.Sequential(\n",
    "                        nn.Conv1d(\n",
    "                            in_channels=2 * prev_sz,\n",
    "                            out_channels=sz,\n",
    "                            kernel_size=ks,\n",
    "                            padding='same',\n",
    "                            bias=False\n",
    "                       ),\n",
    "                       nn.BatchNorm1d(sz, momentum=self.bn_momentum),\n",
    "                       activation(),\n",
    "            )\n",
    "            seqextblocks[f'resize_blc{ind}'] = block\n",
    "\n",
    "        self.seqextractor = nn.ModuleDict(seqextblocks)\n",
    "\n",
    "        self.mapper = block = nn.Sequential(\n",
    "                        nn.Conv1d(\n",
    "                            in_channels=block_sizes[-1],\n",
    "                            out_channels=self.final_ch,\n",
    "                            kernel_size=1,\n",
    "                            padding='same',\n",
    "                       ),\n",
    "                       activation()\n",
    "        )\n",
    "        \n",
    "        self.register_buffer('bins', torch.arange(start=0, end=self.final_ch, step=1, requires_grad=False))\n",
    "        \n",
    "    def feature_extractor(self, x):\n",
    "        x = self.seqextractor['blc0'](x)\n",
    "        \n",
    "        for i in range(len(self.block_sizes) - 1):\n",
    "            x = torch.cat([x, self.seqextractor[f'inv_res_blc{i}'](x)], dim=1)\n",
    "            x = self.seqextractor[f'resize_blc{i}'](x)\n",
    "        return x \n",
    "\n",
    "    def forward(self, x):    \n",
    "        f = self.feature_extractor(x)\n",
    "        x = self.mapper(f)\n",
    "        x = F.adaptive_avg_pool1d(x, 1)\n",
    "        x = x.squeeze(2)\n",
    "        logprobs = F.log_softmax(x, dim=1) \n",
    "        \n",
    "        # soft-argmax operation\n",
    "        x = F.softmax(x, dim=1)\n",
    "        score = (x * self.bins).sum(dim=1)\n",
    "        \n",
    "        return logprobs, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91bf44",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "\n",
    "set_global_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "\n",
    "model_dir = Path(model_dir)\n",
    "model_dir.mkdir(exist_ok=False, parents=True)\n",
    "\n",
    "run_backup_path = model_dir / \"run.py\"\n",
    "\n",
    "shutil.copy(sys.argv[0], run_backup_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = cash_and_preprocess(seqsize=seqsize, \n",
    "                            path_to_training_data=path_to_training_data, \n",
    "                            delimiter=delimiter, \n",
    "                            foldify=foldify, \n",
    "                            use_single_channel=use_single_channel, \n",
    "                            use_reverse_channel=use_reverse_channel,\n",
    "                            use_multisubstate_channel=use_multisubstate_channel,\n",
    "                            preprocess_data=preprocess_data,\n",
    "                            use_validation=use_validation,\n",
    "                            seed=seed\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation (if needed) dataloader creation\n",
    "\n",
    "train_dl, valid_dl = create_dl(train, valid, \n",
    "                               seqsize,\n",
    "                               use_single_channel, use_reverse_channel, use_multisubstate_channel,\n",
    "                               train_batch_size, train_workers,\n",
    "                               valid_batch_size, valid_workers,\n",
    "                               batch_per_epoch,\n",
    "                               SeqDatasetProb,\n",
    "                               shuffle_train=True, shuffle_val=False\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b9d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation\n",
    "device = torch.device(f\"cuda:{gpu}\")\n",
    "\n",
    "model = get_model(\n",
    "    SeqNN=SeqNN,\n",
    "    seqsize=seqsize, \n",
    "    use_single_channel=use_single_channel,\n",
    "    use_reverse_channel=use_reverse_channel,\n",
    "    use_multisubstate_channel=use_multisubstate_channel,\n",
    "    blocks= blocks, \n",
    "    ks=ks, \n",
    "    resize_factor=resize_factor, \n",
    "    se_reduction=se_reduction, \n",
    "    bn_momentum=bn_momentum,\n",
    "    final_ch=final_ch,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss declaration\n",
    "if loss == \"kl\":\n",
    "    criterion = nn.KLDivLoss(reduction= \"batchmean\").to(device)\n",
    "elif loss == \"mse\":\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "else:\n",
    "    raise Exception(\"Wrong loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e957e14",
   "metadata": {},
   "source": [
    "To select the max learning rate for the One Cycle Policy, we used the LR-range test suggested in [Smith, Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base optimizer setup. Will be changed after lr range test.\n",
    "\n",
    "optimizer = get_optimizer(optimizer_name, model.parameters(), .01, weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lr_finder(model=model, optimizer=optimizer, criterion=criterion, train_dl=train_dl, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33fc1e0",
   "metadata": {},
   "source": [
    "<img src=\"img/lrtest.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2ad8a",
   "metadata": {},
   "source": [
    "Here is presented an example of the lr finder output. Lr should be chosen to be on the lowest plateau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af03aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_lr = 10e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd8ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr, div_factor = chosen_lr, 25.0\n",
    "min_lr = max_lr / div_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f73714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    SeqNN=SeqNN,\n",
    "    seqsize=seqsize, \n",
    "    use_single_channel=use_single_channel,\n",
    "    use_reverse_channel=use_reverse_channel,\n",
    "    use_multisubstate_channel=use_multisubstate_channel,\n",
    "    blocks= blocks, \n",
    "    ks=ks, \n",
    "    resize_factor=resize_factor, \n",
    "    se_reduction=se_reduction, \n",
    "    bn_momentum=bn_momentum,\n",
    "    final_ch=final_ch,\n",
    "    device=device,\n",
    ")\n",
    "optimizer = get_optimizer(optimizer_name, model.parameters(), min_lr, weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d5dfe",
   "metadata": {},
   "source": [
    "To train our neural network, we used **One Cycle Policy** with FastAI modifications: \n",
    "\n",
    "* two phases (instead of the original three), \n",
    "* the cosine annealing strategy instead of the linear one, \n",
    "* the AdamW optimizer (weight_decay=0.01) instead of the SGD with momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                                max_lr=max_lr,\n",
    "                                                div_factor=div_factor,\n",
    "                                                steps_per_epoch=batch_per_epoch, \n",
    "                                                epochs=epoch_num, \n",
    "                                                pct_start=0.3,\n",
    "                                                three_phase=\"store_true\"\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model parameters:', int(parameter_count(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44634413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer, p = create_trainer(model, optimizer, scheduler, criterion, device, model_dir, \n",
    "                            use_validation=use_validation, valid_dl=valid_dl)\n",
    "\n",
    "log_dir = model_dir / \"logs\"\n",
    "\n",
    "tb_logger = TensorboardLogger(log_dir=log_dir)\n",
    "tb_logger.attach_output_handler(\n",
    "        trainer,\n",
    "        event_name=Events.ITERATION_COMPLETED,\n",
    "        tag=\"training\",\n",
    "        output_transform=lambda loss: {\"batchloss\": loss},\n",
    ")\n",
    "\n",
    "state = trainer.run(train_dl, max_epochs=epoch_num) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08917c9c",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1fff37",
   "metadata": {},
   "source": [
    "Here is an additional code that you can use to test your trained model on custom data `target`.\n",
    "\n",
    "For the expression measured in yeast grown in complex and defined medium, native yeast promoter expression measurments can be downloaded for [complex](https://zenodo.org/record/4436477/files/Native_complex.csv?download=1) and [defined](https://zenodo.org/record/4436477/files/Native_defined.csv?download=1) medium from the [Zenodo record](https://zenodo.org/record/4436477#.Y5QgZOxBy3J). \n",
    "\n",
    "Results will be written to the `output`. If `target` file includes ground truth expression estimates, `test_results` function will output metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'path_to_target'\n",
    "output = 'path_to_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c72cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:{gpu}\")\n",
    "model = get_model(\n",
    "    SeqNN=SeqNN,\n",
    "    seqsize=seqsize, \n",
    "    use_single_channel=use_single_channel,\n",
    "    use_reverse_channel=use_reverse_channel,\n",
    "    use_multisubstate_channel=use_multisubstate_channel,\n",
    "    blocks= blocks, \n",
    "    ks=ks, \n",
    "    resize_factor=resize_factor, \n",
    "    se_reduction=se_reduction, \n",
    "    bn_momentum=bn_momentum,\n",
    "    final_ch=final_ch,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6353f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results(target, output, \n",
    "             model, model_dir, epoch_num, seqsize, \n",
    "             use_single_channel, use_reverse_channel, use_multisubstate_channel, \n",
    "             preprocess_data, SeqDatasetProb, valid_batch_size, valid_workers, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e670c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
